{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assignment_02.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "interpreter": {
      "hash": "17ed1555cfbb96ddcf655400d6c25a9cebe961c1b69daf25bae91d698acdd2a7"
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 64-bit ('hsh': conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "afb70e09bf4743919f32adb1b3597d53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c2dc9a6ae1354674b5f47c6a6d145cf6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5b4c1dbd41cc4a52a0120e46fcebc1c3",
              "IPY_MODEL_5ca7ce51ff4b464188dff0948f120af4",
              "IPY_MODEL_13ab7c99f72d4519a770f64c285eac3d"
            ]
          }
        },
        "c2dc9a6ae1354674b5f47c6a6d145cf6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5b4c1dbd41cc4a52a0120e46fcebc1c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7d0f3ca067cc4c458fc15e0eb7e940c9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "  3%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_48a794165bce43f99e665a6453ded527"
          }
        },
        "5ca7ce51ff4b464188dff0948f120af4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4feafcdabbc044329384e78204da9757",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 100,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 3,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b50d476f4c0c46fbb3ed4bbf68fa8fc9"
          }
        },
        "13ab7c99f72d4519a770f64c285eac3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b929fa26c7b64d80a6a6159433d171ae",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 3/100 [01:34&lt;50:40, 31.34s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8ff0498cbfd741e49a3256d3a49e7392"
          }
        },
        "7d0f3ca067cc4c458fc15e0eb7e940c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "48a794165bce43f99e665a6453ded527": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4feafcdabbc044329384e78204da9757": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b50d476f4c0c46fbb3ed4bbf68fa8fc9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b929fa26c7b64d80a6a6159433d171ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8ff0498cbfd741e49a3256d3a49e7392": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K29I-OwCEYzW",
        "outputId": "db8b297c-a4b8-457a-b43f-7570135306c7"
      },
      "source": [
        "# Image De-blurring by Supervised Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6yVaO6Miinh"
      },
      "source": [
        "## import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVzeQz6xiini"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "from math import log10\n",
        "from tqdm import tqdm, tqdm_notebook\n",
        "import random\n",
        "import os"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XjATHJULiinj"
      },
      "source": [
        "## load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KhbJoC2miink",
        "outputId": "af549e9e-9f48-462d-af89-aaeca979da8c"
      },
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "directory_data  = './drive/MyDrive/Machine_Learning/'\n",
        "filename_data   = 'assignment_11_data.npz'\n",
        "data            = np.load(os.path.join(directory_data, filename_data))\n",
        "\n",
        "original_train  = data['original_train']\n",
        "blur_train      = data['blur_train']\n",
        "\n",
        "original_test   = data['original_test']\n",
        "blur_test       = data['blur_test']\n",
        "\n",
        "num_data_train  = original_train.shape[0]\n",
        "num_data_test   = original_test.shape[0]\n",
        "\n",
        "print('*************************************************')\n",
        "print('size of original_train :', original_train.shape)\n",
        "print('size of blur_train :', blur_train.shape)\n",
        "print('*************************************************')\n",
        "print('size of original_test :', original_test.shape)\n",
        "print('size of blur_test :', blur_test.shape)\n",
        "print('*************************************************')\n",
        "print('number of training image :', original_train.shape[0])\n",
        "print('height of training image :', original_train.shape[1])\n",
        "print('width of training image :', original_train.shape[2])\n",
        "print('*************************************************')\n",
        "print('number of testing image :', original_test.shape[0])\n",
        "print('height of testing image :', original_test.shape[1])\n",
        "print('width of testing image :', original_test.shape[2])\n",
        "print('*************************************************')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n",
            "*************************************************\n",
            "size of original_train : (200, 256, 256)\n",
            "size of blur_train : (200, 256, 256)\n",
            "*************************************************\n",
            "size of original_test : (100, 256, 256)\n",
            "size of blur_test : (100, 256, 256)\n",
            "*************************************************\n",
            "number of training image : 200\n",
            "height of training image : 256\n",
            "width of training image : 256\n",
            "*************************************************\n",
            "number of testing image : 100\n",
            "height of testing image : 256\n",
            "width of testing image : 256\n",
            "*************************************************\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P6eQd9Uwiinm"
      },
      "source": [
        "## hyper-parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9sIADL6wiinm"
      },
      "source": [
        "device          = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "number_epoch    = 100\n",
        "size_minibatch  = 16\n",
        "learning_rate   = 0.05\n",
        "weight_decay    = 0.000001"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DdIukf5Niinn"
      },
      "source": [
        "## custom data loader for the PyTorch framework"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O1nqMQq5iinn"
      },
      "source": [
        "class dataset(Dataset):\n",
        "    \n",
        "    def __init__(self, original, blur, transform=False):\n",
        "        \n",
        "        self.original   = original\n",
        "        self.blur       = blur \n",
        "        self.transform = transform\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        \n",
        "        original    = self.original[index]\n",
        "        blur        = self.blur[index]\n",
        "        \n",
        "        original    = torch.FloatTensor(original).unsqueeze(dim=0)\n",
        "        blur        = torch.FloatTensor(blur).unsqueeze(dim=0)\n",
        "\n",
        "        if self.transform:\n",
        "\n",
        "            crop_size = [64, 64]\n",
        "            # random crop\n",
        "            top         = random.randint(0, original.shape[1] - crop_size[0])\n",
        "            left        = random.randint(0, original.shape[2] - crop_size[1])\n",
        "            original    = transforms.functional.crop(original, top, left, crop_size[0], crop_size[1])\n",
        "            blur        = transforms.functional.crop(blur, top, left, crop_size[0], crop_size[1])\n",
        "            \n",
        "            # random horizontal flip\n",
        "            if random.random() > 0.5: \n",
        "                original = transforms.functional.hflip(original)\n",
        "                blur = transforms.functional.hflip(blur)\n",
        "\n",
        "            # random vertical flip\n",
        "            if random.random() > 0.5: \n",
        "                original = transforms.functional.vflip(original)\n",
        "                blur = transforms.functional.vflip(blur)\n",
        "\n",
        "        return (original, blur)\n",
        "    \n",
        "    def __len__(self):\n",
        "        \n",
        "        return self.original.shape[0]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4YqJuBMiino"
      },
      "source": [
        "## construct datasets and dataloaders for training and testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7AKae9Giinp"
      },
      "source": [
        "dataset_train_transform = dataset(original_train, blur_train, transform=True)\n",
        "dataset_train           = dataset(original_train, blur_train)\n",
        "dataset_test            = dataset(original_test, blur_test)\n",
        "\n",
        "dataloader_train_transform  = DataLoader(dataset_train_transform, batch_size=size_minibatch, shuffle=True, drop_last=True)\n",
        "# dataloader_train            = DataLoader(dataset_train, batch_size=1, shuffle=False, drop_last=True)\n",
        "dataloader_test             = DataLoader(dataset_test, batch_size=1, shuffle=False, drop_last=True)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5E-WmRRmiinp"
      },
      "source": [
        "## shape of the data when using the data loader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F-Rn4h5Piinq",
        "outputId": "3cec6fc4-8eaa-437f-b979-2b9d179be58a"
      },
      "source": [
        "(original_train, blur_train)  = dataset_train[0]\n",
        "(original_test, blur_test)    = dataset_test[0]\n",
        "(original_train_transform, blur_train_transform)  = dataset_train_transform[0]\n",
        "print('*******************************************************************')\n",
        "print('shape of the original in the training dataset:', original_train.shape)\n",
        "print('shape of the blur in the training dataset:', blur_train.shape)\n",
        "print('*******************************************************************')\n",
        "print('shape of the original in the testing dataset:', original_test.shape)\n",
        "print('shape of the blur in the testing dataset:', blur_test.shape)\n",
        "print('*******************************************************************')\n",
        "print('shape of the original in the training transform dataset:', original_train_transform.shape)\n",
        "print('shape of the blur in the training transform dataset:', blur_train_transform.shape)\n",
        "print('*******************************************************************')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*******************************************************************\n",
            "shape of the original in the training dataset: torch.Size([1, 256, 256])\n",
            "shape of the blur in the training dataset: torch.Size([1, 256, 256])\n",
            "*******************************************************************\n",
            "shape of the original in the testing dataset: torch.Size([1, 256, 256])\n",
            "shape of the blur in the testing dataset: torch.Size([1, 256, 256])\n",
            "*******************************************************************\n",
            "shape of the original in the training transform dataset: torch.Size([1, 64, 64])\n",
            "shape of the blur in the training transform dataset: torch.Size([1, 64, 64])\n",
            "*******************************************************************\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKuKatRfiinr"
      },
      "source": [
        "## class for the neural network "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6EkSWG7vkMKa"
      },
      "source": [
        "##########################################################################\n",
        "def conv(in_channels, out_channels, kernel_size, bias=False, stride = 1):\n",
        "    return nn.Conv2d(\n",
        "        in_channels, out_channels, kernel_size,\n",
        "        padding=(kernel_size//2), bias=bias, stride = stride)\n",
        "\n",
        "\n",
        "##########################################################################\n",
        "## Channel Attention Layer\n",
        "class CALayer(nn.Module):\n",
        "    def __init__(self, channel, reduction=16, bias=False):\n",
        "        super(CALayer, self).__init__()\n",
        "        # global average pooling: feature --> point\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "        # feature channel downscale and upscale --> channel weight\n",
        "        self.conv_du = nn.Sequential(\n",
        "                nn.Conv2d(channel, channel // reduction, 1, padding=0, bias=bias),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.Conv2d(channel // reduction, channel, 1, padding=0, bias=bias),\n",
        "                nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        y = self.avg_pool(x)\n",
        "        y = self.conv_du(y)\n",
        "        return x * y\n",
        "\n",
        "\n",
        "##########################################################################\n",
        "## Channel Attention Block (CAB)\n",
        "class CAB(nn.Module):\n",
        "    def __init__(self, n_feat, kernel_size, reduction, bias, act):\n",
        "        super(CAB, self).__init__()\n",
        "        modules_body = []\n",
        "        modules_body.append(conv(n_feat, n_feat, kernel_size, bias=bias))\n",
        "        modules_body.append(act)\n",
        "        modules_body.append(conv(n_feat, n_feat, kernel_size, bias=bias))\n",
        "\n",
        "        self.CA = CALayer(n_feat, reduction, bias=bias)\n",
        "        self.body = nn.Sequential(*modules_body)\n",
        "\n",
        "    def forward(self, x):\n",
        "        res = self.body(x)\n",
        "        res = self.CA(res)\n",
        "        res += x\n",
        "        return res\n",
        "\n",
        "##########################################################################\n",
        "## Supervised Attention Module\n",
        "class SAM(nn.Module):\n",
        "    def __init__(self, n_feat, kernel_size, bias):\n",
        "        super(SAM, self).__init__()\n",
        "        self.conv1 = conv(n_feat, n_feat, kernel_size, bias=bias)\n",
        "        self.conv2 = conv(n_feat, 1, kernel_size, bias=bias)\n",
        "        self.conv3 = conv(1, n_feat, kernel_size, bias=bias)\n",
        "\n",
        "    def forward(self, x, x_img):\n",
        "        x1 = self.conv1(x)\n",
        "        img = self.conv2(x) + x_img\n",
        "        x2 = torch.sigmoid(self.conv3(img))\n",
        "        x1 = x1*x2\n",
        "        x1 = x1+x\n",
        "        return x1, img\n",
        "\n",
        "##########################################################################\n",
        "## U-Net\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, n_feat, kernel_size, reduction, act, bias, scale_unetfeats, csff):\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        self.encoder_level1 = [CAB(n_feat,                     kernel_size, reduction, bias=bias, act=act) for _ in range(2)]\n",
        "        self.encoder_level2 = [CAB(n_feat+scale_unetfeats,     kernel_size, reduction, bias=bias, act=act) for _ in range(2)]\n",
        "        self.encoder_level3 = [CAB(n_feat+(scale_unetfeats*2), kernel_size, reduction, bias=bias, act=act) for _ in range(2)]\n",
        "\n",
        "        self.encoder_level1 = nn.Sequential(*self.encoder_level1)\n",
        "        self.encoder_level2 = nn.Sequential(*self.encoder_level2)\n",
        "        self.encoder_level3 = nn.Sequential(*self.encoder_level3)\n",
        "\n",
        "        self.down12  = DownSample(n_feat, scale_unetfeats)\n",
        "        self.down23  = DownSample(n_feat+scale_unetfeats, scale_unetfeats)\n",
        "\n",
        "        # Cross Stage Feature Fusion (CSFF)\n",
        "        if csff:\n",
        "            self.csff_enc1 = nn.Conv2d(n_feat,                     n_feat,                     kernel_size=1, bias=bias)\n",
        "            self.csff_enc2 = nn.Conv2d(n_feat+scale_unetfeats,     n_feat+scale_unetfeats,     kernel_size=1, bias=bias)\n",
        "            self.csff_enc3 = nn.Conv2d(n_feat+(scale_unetfeats*2), n_feat+(scale_unetfeats*2), kernel_size=1, bias=bias)\n",
        "\n",
        "            self.csff_dec1 = nn.Conv2d(n_feat,                     n_feat,                     kernel_size=1, bias=bias)\n",
        "            self.csff_dec2 = nn.Conv2d(n_feat+scale_unetfeats,     n_feat+scale_unetfeats,     kernel_size=1, bias=bias)\n",
        "            self.csff_dec3 = nn.Conv2d(n_feat+(scale_unetfeats*2), n_feat+(scale_unetfeats*2), kernel_size=1, bias=bias)\n",
        "\n",
        "    def forward(self, x, encoder_outs=None, decoder_outs=None):\n",
        "        enc1 = self.encoder_level1(x)\n",
        "        if (encoder_outs is not None) and (decoder_outs is not None):\n",
        "            enc1 = enc1 + self.csff_enc1(encoder_outs[0]) + self.csff_dec1(decoder_outs[0])\n",
        "\n",
        "        x = self.down12(enc1)\n",
        "\n",
        "        enc2 = self.encoder_level2(x)\n",
        "        if (encoder_outs is not None) and (decoder_outs is not None):\n",
        "            enc2 = enc2 + self.csff_enc2(encoder_outs[1]) + self.csff_dec2(decoder_outs[1])\n",
        "\n",
        "        x = self.down23(enc2)\n",
        "\n",
        "        enc3 = self.encoder_level3(x)\n",
        "        if (encoder_outs is not None) and (decoder_outs is not None):\n",
        "            enc3 = enc3 + self.csff_enc3(encoder_outs[2]) + self.csff_dec3(decoder_outs[2])\n",
        "        \n",
        "        return [enc1, enc2, enc3]\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, n_feat, kernel_size, reduction, act, bias, scale_unetfeats):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        self.decoder_level1 = [CAB(n_feat,                     kernel_size, reduction, bias=bias, act=act) for _ in range(2)]\n",
        "        self.decoder_level2 = [CAB(n_feat+scale_unetfeats,     kernel_size, reduction, bias=bias, act=act) for _ in range(2)]\n",
        "        self.decoder_level3 = [CAB(n_feat+(scale_unetfeats*2), kernel_size, reduction, bias=bias, act=act) for _ in range(2)]\n",
        "\n",
        "        self.decoder_level1 = nn.Sequential(*self.decoder_level1)\n",
        "        self.decoder_level2 = nn.Sequential(*self.decoder_level2)\n",
        "        self.decoder_level3 = nn.Sequential(*self.decoder_level3)\n",
        "\n",
        "        self.skip_attn1 = CAB(n_feat,                 kernel_size, reduction, bias=bias, act=act)\n",
        "        self.skip_attn2 = CAB(n_feat+scale_unetfeats, kernel_size, reduction, bias=bias, act=act)\n",
        "\n",
        "        self.up21  = SkipUpSample(n_feat, scale_unetfeats)\n",
        "        self.up32  = SkipUpSample(n_feat+scale_unetfeats, scale_unetfeats)\n",
        "\n",
        "    def forward(self, outs):\n",
        "        enc1, enc2, enc3 = outs\n",
        "        dec3 = self.decoder_level3(enc3)\n",
        "\n",
        "        x = self.up32(dec3, self.skip_attn2(enc2))\n",
        "        dec2 = self.decoder_level2(x)\n",
        "\n",
        "        x = self.up21(dec2, self.skip_attn1(enc1))\n",
        "        dec1 = self.decoder_level1(x)\n",
        "\n",
        "        return [dec1,dec2,dec3]\n",
        "\n",
        "##########################################################################\n",
        "##---------- Resizing Modules ----------    \n",
        "class DownSample(nn.Module):\n",
        "    def __init__(self, in_channels,s_factor):\n",
        "        super(DownSample, self).__init__()\n",
        "        self.down = nn.Sequential(nn.Upsample(scale_factor=0.5, mode='bilinear', align_corners=False),\n",
        "                                  nn.Conv2d(in_channels, in_channels+s_factor, 1, stride=1, padding=0, bias=False))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.down(x)\n",
        "        return x\n",
        "\n",
        "class UpSample(nn.Module):\n",
        "    def __init__(self, in_channels,s_factor):\n",
        "        super(UpSample, self).__init__()\n",
        "        self.up = nn.Sequential(nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False),\n",
        "                                nn.Conv2d(in_channels+s_factor, in_channels, 1, stride=1, padding=0, bias=False))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.up(x)\n",
        "        return x\n",
        "\n",
        "class SkipUpSample(nn.Module):\n",
        "    def __init__(self, in_channels,s_factor):\n",
        "        super(SkipUpSample, self).__init__()\n",
        "        self.up = nn.Sequential(nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False),\n",
        "                                nn.Conv2d(in_channels+s_factor, in_channels, 1, stride=1, padding=0, bias=False))\n",
        "\n",
        "    def forward(self, x, y):\n",
        "        x = self.up(x)\n",
        "        x = x + y\n",
        "        return x\n",
        "\n",
        "##########################################################################\n",
        "## Original Resolution Block (ORB)\n",
        "class ORB(nn.Module):\n",
        "    def __init__(self, n_feat, kernel_size, reduction, act, bias, num_cab):\n",
        "        super(ORB, self).__init__()\n",
        "        modules_body = []\n",
        "        modules_body = [CAB(n_feat, kernel_size, reduction, bias=bias, act=act) for _ in range(num_cab)]\n",
        "        modules_body.append(conv(n_feat, n_feat, kernel_size))\n",
        "        self.body = nn.Sequential(*modules_body)\n",
        "\n",
        "    def forward(self, x):\n",
        "        res = self.body(x)\n",
        "        res += x\n",
        "        return res\n",
        "\n",
        "##########################################################################\n",
        "class ORSNet(nn.Module):\n",
        "    def __init__(self, n_feat, scale_orsnetfeats, kernel_size, reduction, act, bias, scale_unetfeats, num_cab):\n",
        "        super(ORSNet, self).__init__()\n",
        "\n",
        "        self.orb1 = ORB(n_feat+scale_orsnetfeats, kernel_size, reduction, act, bias, num_cab)\n",
        "        self.orb2 = ORB(n_feat+scale_orsnetfeats, kernel_size, reduction, act, bias, num_cab)\n",
        "        self.orb3 = ORB(n_feat+scale_orsnetfeats, kernel_size, reduction, act, bias, num_cab)\n",
        "\n",
        "        self.up_enc1 = UpSample(n_feat, scale_unetfeats)\n",
        "        self.up_dec1 = UpSample(n_feat, scale_unetfeats)\n",
        "\n",
        "        self.up_enc2 = nn.Sequential(UpSample(n_feat+scale_unetfeats, scale_unetfeats), UpSample(n_feat, scale_unetfeats))\n",
        "        self.up_dec2 = nn.Sequential(UpSample(n_feat+scale_unetfeats, scale_unetfeats), UpSample(n_feat, scale_unetfeats))\n",
        "\n",
        "        self.conv_enc1 = nn.Conv2d(n_feat, n_feat+scale_orsnetfeats, kernel_size=1, bias=bias)\n",
        "        self.conv_enc2 = nn.Conv2d(n_feat, n_feat+scale_orsnetfeats, kernel_size=1, bias=bias)\n",
        "        self.conv_enc3 = nn.Conv2d(n_feat, n_feat+scale_orsnetfeats, kernel_size=1, bias=bias)\n",
        "\n",
        "        self.conv_dec1 = nn.Conv2d(n_feat, n_feat+scale_orsnetfeats, kernel_size=1, bias=bias)\n",
        "        self.conv_dec2 = nn.Conv2d(n_feat, n_feat+scale_orsnetfeats, kernel_size=1, bias=bias)\n",
        "        self.conv_dec3 = nn.Conv2d(n_feat, n_feat+scale_orsnetfeats, kernel_size=1, bias=bias)\n",
        "\n",
        "    def forward(self, x, encoder_outs, decoder_outs):\n",
        "        x = self.orb1(x)\n",
        "        x = x + self.conv_enc1(encoder_outs[0]) + self.conv_dec1(decoder_outs[0])\n",
        "\n",
        "        x = self.orb2(x)\n",
        "        x = x + self.conv_enc2(self.up_enc1(encoder_outs[1])) + self.conv_dec2(self.up_dec1(decoder_outs[1]))\n",
        "\n",
        "        x = self.orb3(x)\n",
        "        x = x + self.conv_enc3(self.up_enc2(encoder_outs[2])) + self.conv_dec3(self.up_dec2(decoder_outs[2]))\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "##########################################################################\n",
        "class MPRNet(nn.Module):\n",
        "    def __init__(self, in_c=1, out_c=1, n_feat=96, scale_unetfeats=48, scale_orsnetfeats=32, num_cab=8, kernel_size=3, reduction=4, bias=False):\n",
        "        super(MPRNet, self).__init__()\n",
        "\n",
        "        act=nn.PReLU()\n",
        "        self.shallow_feat1 = nn.Sequential(conv(in_c, n_feat, kernel_size, bias=bias), CAB(n_feat,kernel_size, reduction, bias=bias, act=act))\n",
        "        self.shallow_feat2 = nn.Sequential(conv(in_c, n_feat, kernel_size, bias=bias), CAB(n_feat,kernel_size, reduction, bias=bias, act=act))\n",
        "        self.shallow_feat3 = nn.Sequential(conv(in_c, n_feat, kernel_size, bias=bias), CAB(n_feat,kernel_size, reduction, bias=bias, act=act))\n",
        "\n",
        "        # Cross Stage Feature Fusion (CSFF)\n",
        "        self.stage1_encoder = Encoder(n_feat, kernel_size, reduction, act, bias, scale_unetfeats, csff=False)\n",
        "        self.stage1_decoder = Decoder(n_feat, kernel_size, reduction, act, bias, scale_unetfeats)\n",
        "\n",
        "        self.stage2_encoder = Encoder(n_feat, kernel_size, reduction, act, bias, scale_unetfeats, csff=True)\n",
        "        self.stage2_decoder = Decoder(n_feat, kernel_size, reduction, act, bias, scale_unetfeats)\n",
        "\n",
        "        self.stage3_orsnet = ORSNet(n_feat, scale_orsnetfeats, kernel_size, reduction, act, bias, scale_unetfeats, num_cab)\n",
        "\n",
        "        self.sam12 = SAM(n_feat, kernel_size=1, bias=bias)\n",
        "        self.sam23 = SAM(n_feat, kernel_size=1, bias=bias)\n",
        "        \n",
        "        self.concat12  = conv(n_feat*2, n_feat, kernel_size, bias=bias)\n",
        "        self.concat23  = conv(n_feat*2, n_feat+scale_orsnetfeats, kernel_size, bias=bias)\n",
        "        self.tail     = conv(n_feat+scale_orsnetfeats, out_c, kernel_size, bias=bias)\n",
        "\n",
        "    def forward(self, x3_img):\n",
        "        # Original-resolution Image for Stage 3\n",
        "        H = x3_img.size(2)\n",
        "        W = x3_img.size(3)\n",
        "\n",
        "        # Multi-Patch Hierarchy: Split Image into four non-overlapping patches\n",
        "\n",
        "        # Two Patches for Stage 2\n",
        "        x2top_img  = x3_img[:,:,0:int(H/2),:]\n",
        "        x2bot_img  = x3_img[:,:,int(H/2):H,:]\n",
        "\n",
        "        # Four Patches for Stage 1\n",
        "        x1ltop_img = x2top_img[:,:,:,0:int(W/2)]\n",
        "        x1rtop_img = x2top_img[:,:,:,int(W/2):W]\n",
        "        x1lbot_img = x2bot_img[:,:,:,0:int(W/2)]\n",
        "        x1rbot_img = x2bot_img[:,:,:,int(W/2):W]\n",
        "\n",
        "        ##-------------------------------------------\n",
        "        ##-------------- Stage 1---------------------\n",
        "        ##-------------------------------------------\n",
        "        ## Compute Shallow Features\n",
        "        x1ltop = self.shallow_feat1(x1ltop_img)\n",
        "        x1rtop = self.shallow_feat1(x1rtop_img)\n",
        "        x1lbot = self.shallow_feat1(x1lbot_img)\n",
        "        x1rbot = self.shallow_feat1(x1rbot_img)\n",
        "        \n",
        "        ## Process features of all 4 patches with Encoder of Stage 1\n",
        "        feat1_ltop = self.stage1_encoder(x1ltop)\n",
        "        feat1_rtop = self.stage1_encoder(x1rtop)\n",
        "        feat1_lbot = self.stage1_encoder(x1lbot)\n",
        "        feat1_rbot = self.stage1_encoder(x1rbot)\n",
        "        \n",
        "        ## Concat deep features\n",
        "        feat1_top = [torch.cat((k,v), 3) for k,v in zip(feat1_ltop,feat1_rtop)]\n",
        "        feat1_bot = [torch.cat((k,v), 3) for k,v in zip(feat1_lbot,feat1_rbot)]\n",
        "        \n",
        "        ## Pass features through Decoder of Stage 1\n",
        "        res1_top = self.stage1_decoder(feat1_top)\n",
        "        res1_bot = self.stage1_decoder(feat1_bot)\n",
        "\n",
        "        ## Apply Supervised Attention Module (SAM)\n",
        "        x2top_samfeats, stage1_img_top = self.sam12(res1_top[0], x2top_img)\n",
        "        x2bot_samfeats, stage1_img_bot = self.sam12(res1_bot[0], x2bot_img)\n",
        "\n",
        "        ## Output image at Stage 1\n",
        "        stage1_img = torch.cat([stage1_img_top, stage1_img_bot],2) \n",
        "        ##-------------------------------------------\n",
        "        ##-------------- Stage 2---------------------\n",
        "        ##-------------------------------------------\n",
        "        ## Compute Shallow Features\n",
        "        x2top  = self.shallow_feat2(x2top_img)\n",
        "        x2bot  = self.shallow_feat2(x2bot_img)\n",
        "\n",
        "        ## Concatenate SAM features of Stage 1 with shallow features of Stage 2\n",
        "        x2top_cat = self.concat12(torch.cat([x2top, x2top_samfeats], 1))\n",
        "        x2bot_cat = self.concat12(torch.cat([x2bot, x2bot_samfeats], 1))\n",
        "\n",
        "        ## Process features of both patches with Encoder of Stage 2\n",
        "        feat2_top = self.stage2_encoder(x2top_cat, feat1_top, res1_top)\n",
        "        feat2_bot = self.stage2_encoder(x2bot_cat, feat1_bot, res1_bot)\n",
        "\n",
        "        ## Concat deep features\n",
        "        feat2 = [torch.cat((k,v), 2) for k,v in zip(feat2_top,feat2_bot)]\n",
        "\n",
        "        ## Pass features through Decoder of Stage 2\n",
        "        res2 = self.stage2_decoder(feat2)\n",
        "\n",
        "        ## Apply SAM\n",
        "        x3_samfeats, stage2_img = self.sam23(res2[0], x3_img)\n",
        "\n",
        "\n",
        "        ##-------------------------------------------\n",
        "        ##-------------- Stage 3---------------------\n",
        "        ##-------------------------------------------\n",
        "        ## Compute Shallow Features\n",
        "        x3     = self.shallow_feat3(x3_img)\n",
        "\n",
        "        ## Concatenate SAM features of Stage 2 with shallow features of Stage 3\n",
        "        x3_cat = self.concat23(torch.cat([x3, x3_samfeats], 1))\n",
        "        \n",
        "        x3_cat = self.stage3_orsnet(x3_cat, feat2, res2)\n",
        "\n",
        "        stage3_img = self.tail(x3_cat)\n",
        "\n",
        "        return [stage3_img+x3_img, stage2_img, stage1_img]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mg7VWL9Miint"
      },
      "source": [
        "## build network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hlDVgAXiint"
      },
      "source": [
        "model       = MPRNet().to(device)\n",
        "optimizer   = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTyV7_8jrUZ7",
        "outputId": "984ae202-b7c6-42f8-81ac-f1d2d5c6d6f6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "x = torch.rand(2, 1, 128, 128).to(device)\n",
        "x = model(x)\n",
        "print(x[0].shape, x[1].shape, x[2].shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 1, 128, 128]) torch.Size([2, 1, 128, 128]) torch.Size([2, 1, 128, 128])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3680: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  \"The default behavior for interpolate/upsample with float scale_factor changed \"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DTXFg_fwiinu"
      },
      "source": [
        "## compute the prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7nKrCq5Biinu"
      },
      "source": [
        "def compute_prediction(model, input):\n",
        "    # ==================================================\n",
        "    # fill up the blank\n",
        "    #\n",
        "    prediction = model(input)\n",
        "    # \n",
        "    # ==================================================\n",
        "\n",
        "    return prediction"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z3oIYUXkiinv"
      },
      "source": [
        "## compute the loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Kt3dsKaiinv"
      },
      "source": [
        "class CharbonnierLoss(nn.Module):\n",
        "    \"\"\"Charbonnier Loss (L1)\"\"\"\n",
        "\n",
        "    def __init__(self, eps=1e-3):\n",
        "        super(CharbonnierLoss, self).__init__()\n",
        "        self.eps = eps\n",
        "\n",
        "    def forward(self, x, y):\n",
        "        diff = x - y\n",
        "        loss = torch.mean(torch.sqrt((diff * diff) + (self.eps*self.eps)))\n",
        "        return loss\n",
        "\n",
        "class EdgeLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(EdgeLoss, self).__init__()\n",
        "        k = torch.Tensor([[.05, .25, .4, .25, .05]])\n",
        "        self.kernel = torch.matmul(k.t(),k).unsqueeze(0).repeat(1,1,1,1)\n",
        "        if torch.cuda.is_available():\n",
        "            self.kernel = self.kernel.cuda()\n",
        "        self.loss = CharbonnierLoss()\n",
        "\n",
        "    def conv_gauss(self, img):\n",
        "        n_channels, _, kw, kh = self.kernel.shape\n",
        "        img = F.pad(img, (kw//2, kh//2, kw//2, kh//2), mode='replicate')\n",
        "        # print(self.kernel, n_channels)\n",
        "        return F.conv2d(img, self.kernel, groups=n_channels)\n",
        "\n",
        "    def laplacian_kernel(self, current):\n",
        "        filtered    = self.conv_gauss(current)    # filter\n",
        "        down        = filtered[:,:,::2,::2]               # downsample\n",
        "        new_filter  = torch.zeros_like(filtered)\n",
        "        new_filter[:,:,::2,::2] = down*4                  # upsample\n",
        "        filtered    = self.conv_gauss(new_filter) # filter\n",
        "        diff = current - filtered\n",
        "        return diff\n",
        "\n",
        "    def forward(self, x, y):\n",
        "        loss = self.loss(self.laplacian_kernel(x), self.laplacian_kernel(y))\n",
        "        return loss"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JUwA_jejiinw"
      },
      "source": [
        "## compute the accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rssnwimtiinw"
      },
      "source": [
        "def compute_accuracy(prediction, label):\n",
        "\n",
        "    prediction  = prediction.squeeze(axis=1)\n",
        "    label       = label.squeeze(axis=1)\n",
        "    mse_loss    = torch.mean((prediction - label) ** 2)\n",
        "\n",
        "    if mse_loss == 0.0:\n",
        "        psnr = 100\n",
        "    else:\n",
        "        psnr = 10 * torch.log10(1 / mse_loss)\n",
        "\n",
        "    psnr = psnr.item()\n",
        "    \n",
        "    return psnr"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m61bwiE5iinx"
      },
      "source": [
        "## variables for the learning curve"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FhwZv7mciinx"
      },
      "source": [
        "loss_mean_train     = np.zeros(number_epoch)\n",
        "loss_std_train      = np.zeros(number_epoch)\n",
        "accuracy_mean_train = np.zeros(number_epoch)\n",
        "accuracy_std_train  = np.zeros(number_epoch)\n",
        "\n",
        "loss_mean_test      = np.zeros(number_epoch)\n",
        "loss_std_test       = np.zeros(number_epoch)\n",
        "accuracy_mean_test  = np.zeros(number_epoch)\n",
        "accuracy_std_test   = np.zeros(number_epoch)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1K0w-Amiinx"
      },
      "source": [
        "## train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Er1jYEpwiiny"
      },
      "source": [
        "def train(model, dataloader):\n",
        "\n",
        "    loss_epoch      = []\n",
        "    accuracy_epoch  = []\n",
        "\n",
        "    model.train()\n",
        "    criterion_char = CharbonnierLoss()\n",
        "    criterion_edge = EdgeLoss()\n",
        "    criterion_mse = nn.MSELoss()\n",
        "\n",
        "    for index_batch, (original, blur) in enumerate(dataloader):\n",
        "\n",
        "        original    = original.to(device)\n",
        "        blur        = blur.to(device)\n",
        "        \n",
        "        restored = compute_prediction(model, blur)\n",
        " \n",
        "        # Compute loss at each stage\n",
        "        # loss_char = np.sum([criterion_char(restored[j],original) for j in range(len(restored))])\n",
        "        # loss_edge = np.sum([criterion_edge(restored[j],original) for j in range(len(restored))])\n",
        "        # loss = (loss_char) + (0.05*loss_edge)\n",
        "        loss = criterion_mse(restored[0], original)\n",
        "\n",
        "        accuracy    = compute_accuracy(restored[0], original)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        loss_epoch.append(loss.item())\n",
        "        accuracy_epoch.append(accuracy)\n",
        "\n",
        "    loss_mean_epoch     = np.mean(loss_epoch)\n",
        "    loss_std_epoch      = np.std(loss_epoch)\n",
        "\n",
        "    accuracy_mean_epoch = np.mean(accuracy_epoch)\n",
        "    accuracy_std_epoch  = np.std(accuracy_epoch)\n",
        "\n",
        "    loss        = {'mean' : loss_mean_epoch, 'std' : loss_std_epoch}\n",
        "    accuracy    = {'mean' : accuracy_mean_epoch, 'std' : accuracy_std_epoch}\n",
        "\n",
        "    return (loss, accuracy)    \n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QhzUUjuYiiny"
      },
      "source": [
        "## test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lf1itAEKiiny"
      },
      "source": [
        "def test(model, dataloader):\n",
        "\n",
        "    loss_epoch      = []\n",
        "    accuracy_epoch  = []\n",
        "\n",
        "    model.eval()\n",
        "    criterion_char = CharbonnierLoss()\n",
        "    criterion_edge = EdgeLoss()\n",
        "    criterion_mse = nn.MSELoss()\n",
        "\n",
        "    for index_batch, (original, blur) in enumerate(dataloader):\n",
        "\n",
        "        original    = original.to(device)\n",
        "        blur        = blur.to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            restored = compute_prediction(model, blur)\n",
        "\n",
        "        # Compute loss at each stage\n",
        "        # loss_char = np.sum([criterion_char(restored[j],original) for j in range(len(restored))])\n",
        "        # loss_edge = np.sum([criterion_edge(restored[j],original) for j in range(len(restored))])\n",
        "        # loss = (loss_char) + (0.05*loss_edge)\n",
        "        loss = criterion_mse(restored[0], original)\n",
        "\n",
        "        restored    = restored[0]\n",
        "        accuracy    = compute_accuracy(restored, original)\n",
        "\n",
        "        loss_epoch.append(loss.item())\n",
        "        accuracy_epoch.append(accuracy)\n",
        "\n",
        "    loss_mean_epoch     = np.mean(loss_epoch)\n",
        "    loss_std_epoch      = np.std(loss_epoch)\n",
        "\n",
        "    accuracy_mean_epoch = np.mean(accuracy_epoch)\n",
        "    accuracy_std_epoch  = np.std(accuracy_epoch)\n",
        "\n",
        "    loss        = {'mean' : loss_mean_epoch, 'std' : loss_std_epoch}\n",
        "    accuracy    = {'mean' : accuracy_mean_epoch, 'std' : accuracy_std_epoch}\n",
        "\n",
        "    return (loss, accuracy)    "
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3gUxX9Yiinz"
      },
      "source": [
        "## train and test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324,
          "referenced_widgets": [
            "afb70e09bf4743919f32adb1b3597d53",
            "c2dc9a6ae1354674b5f47c6a6d145cf6",
            "5b4c1dbd41cc4a52a0120e46fcebc1c3",
            "5ca7ce51ff4b464188dff0948f120af4",
            "13ab7c99f72d4519a770f64c285eac3d",
            "7d0f3ca067cc4c458fc15e0eb7e940c9",
            "48a794165bce43f99e665a6453ded527",
            "4feafcdabbc044329384e78204da9757",
            "b50d476f4c0c46fbb3ed4bbf68fa8fc9",
            "b929fa26c7b64d80a6a6159433d171ae",
            "8ff0498cbfd741e49a3256d3a49e7392"
          ]
        },
        "id": "I1Het53eiinz",
        "outputId": "72662c76-d8e3-4ec7-ad6c-2c47e0e6a6de"
      },
      "source": [
        "# ================================================================================\n",
        "# \n",
        "# iterations for epochs\n",
        "#\n",
        "# ================================================================================\n",
        "for i in tqdm_notebook(range(number_epoch)):\n",
        "    \n",
        "    # ================================================================================\n",
        "    # \n",
        "    # training\n",
        "    #\n",
        "    # ================================================================================\n",
        "\n",
        "    (loss_train, accuracy_train) = train(model, dataloader_train_transform)\n",
        "\n",
        "    loss_mean_train[i]      = loss_train['mean']\n",
        "    loss_std_train[i]       = loss_train['std']\n",
        "\n",
        "    accuracy_mean_train[i]  = accuracy_train['mean']\n",
        "    accuracy_std_train[i]   = accuracy_train['std']\n",
        "\n",
        "    # ================================================================================\n",
        "    # \n",
        "    # testing\n",
        "    #\n",
        "    # ================================================================================\n",
        "    (loss_test, accuracy_test) = test(model, dataloader_test)\n",
        "\n",
        "    loss_mean_test[i]      = loss_test['mean']\n",
        "    loss_std_test[i]       = loss_test['std']\n",
        "\n",
        "    accuracy_mean_test[i]  = accuracy_test['mean']\n",
        "    accuracy_std_test[i]   = accuracy_test['std']\n",
        "\n",
        "    print(f\"epoch : {i}\")\n",
        "    print(f\"\\ttrain loss : {loss_train['mean']}, train acc : {accuracy_train['mean']}\")\n",
        "    print(f\"\\ttest loss  : {loss_test['mean']},  test acc  : {accuracy_test['mean']}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "afb70e09bf4743919f32adb1b3597d53",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/100 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3680: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  \"The default behavior for interpolate/upsample with float scale_factor changed \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch : 0\n",
            "\ttrain loss : nan, train acc : nan\n",
            "\ttest loss  : nan,  test acc  : nan\n",
            "epoch : 1\n",
            "\ttrain loss : nan, train acc : nan\n",
            "\ttest loss  : nan,  test acc  : nan\n",
            "epoch : 2\n",
            "\ttrain loss : nan, train acc : nan\n",
            "\ttest loss  : nan,  test acc  : nan\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MoC_whDwiin0"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5X7Bb19siin0"
      },
      "source": [
        "# functions for visualizing the results "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZfI2EWeviin0"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1rrZCx7Uiin1"
      },
      "source": [
        "## plot curve"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Cn7IS4Eiin1"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFFC4JEBiin1"
      },
      "source": [
        "def plot_data_grid(data, index_data, nRow, nCol):\n",
        "    \n",
        "    size_col = 1.5\n",
        "    size_row = 1.5\n",
        "\n",
        "    fig, axes = plt.subplots(nRow, nCol, constrained_layout=True, figsize=(nCol * size_col, nRow * size_row))\n",
        "\n",
        "    for i in range(nRow):\n",
        "        for j in range(nCol):\n",
        "\n",
        "            k       = i * nCol + j\n",
        "            index   = index_data[k]\n",
        "\n",
        "            axes[i, j].imshow(data[index], cmap='gray', vmin=0, vmax=1)\n",
        "            axes[i, j].xaxis.set_visible(False)\n",
        "            axes[i, j].yaxis.set_visible(False)\n",
        "\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sc7sIOXOiin2"
      },
      "source": [
        "def plot_data_tensor_grid(data, index_data, nRow, nCol):\n",
        "    \n",
        "    size_col = 1.5\n",
        "    size_row = 1.5\n",
        "\n",
        "    fig, axes = plt.subplots(nRow, nCol, constrained_layout=True, figsize=(nCol * size_col, nRow * size_row))\n",
        "\n",
        "    data = data.detach().cpu().squeeze(axis=1)\n",
        "\n",
        "    for i in range(nRow):\n",
        "        for j in range(nCol):\n",
        "\n",
        "            k       = i * nCol + j\n",
        "            index   = index_data[k]\n",
        "\n",
        "            axes[i, j].imshow(data[index], cmap='gray', vmin=0, vmax=1)\n",
        "            axes[i, j].xaxis.set_visible(False)\n",
        "            axes[i, j].yaxis.set_visible(False)\n",
        "\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Divc-qKLiin2"
      },
      "source": [
        "def plot_curve_error(data_mean, data_std, x_label, y_label, title):\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.title(title)\n",
        "\n",
        "    alpha = 0.3\n",
        "    \n",
        "    plt.plot(range(len(data_mean)), data_mean, '-', color = 'red')\n",
        "    plt.fill_between(range(len(data_mean)), data_mean - data_std, data_mean + data_std, facecolor = 'blue', alpha = alpha) \n",
        "    \n",
        "    plt.xlabel(x_label)\n",
        "    plt.ylabel(y_label)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMO5A4aXiin3"
      },
      "source": [
        "def print_curve(data, index):\n",
        "    \n",
        "    for i in range(len(index)):\n",
        "\n",
        "        idx = index[i]\n",
        "        val = data[idx]\n",
        "\n",
        "        print('index = %2d, value = %12.10f' % (idx, val))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXYGcGxxiin3"
      },
      "source": [
        "def get_data_last(data, index_start):\n",
        "\n",
        "    data_last = data[index_start:]\n",
        "\n",
        "    return data_last"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGGKzEIpiin3"
      },
      "source": [
        "def get_max_last_range(data, index_start):\n",
        "\n",
        "    data_range = get_data_last(data, index_start)\n",
        "    value = data_range.max()\n",
        "\n",
        "    return value"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hj9RlRVUiin4"
      },
      "source": [
        "def get_min_last_range(data, index_start):\n",
        "\n",
        "    data_range = get_data_last(data, index_start)\n",
        "    value = data_range.min()\n",
        "\n",
        "    return value"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R26Q1Vpfiin4"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbHYNIuDiin4"
      },
      "source": [
        "# functions for presenting the results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yaBwP4zhiin4"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHTeRjC_iin5"
      },
      "source": [
        "def function_result_01():\n",
        "\n",
        "    print('[plot examples of the training original images]')\n",
        "    print('') \n",
        "\n",
        "    nRow = 8\n",
        "    nCol = 6\n",
        "    index_data      = np.arange(0, nRow * nCol)\n",
        "    data_train, _   = dataset_train[index_data]\n",
        "    data_train      = data_train[0]\n",
        "    \n",
        "    plot_data_grid(data_train, index_data, nRow, nCol)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZRQgONDiin5"
      },
      "source": [
        "def function_result_02():\n",
        "\n",
        "    print('[plot examples of the training blur images]')\n",
        "    print('') \n",
        "    \n",
        "    nRow = 8\n",
        "    nCol = 6\n",
        "    index_data      = np.arange(0, nRow * nCol)\n",
        "    _, data_train   = dataset_train[index_data]\n",
        "    data_train      = data_train[0]\n",
        "    \n",
        "    plot_data_grid(data_train, index_data, nRow, nCol)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_5emj8Siin5"
      },
      "source": [
        "def function_result_03():\n",
        "\n",
        "    print('[plot examples of the training de-blurring results]')\n",
        "    print('') \n",
        "\n",
        "    nRow = 8\n",
        "    nCol = 6\n",
        "    index_data          = np.arange(0, nRow * nCol)\n",
        "    _, data_train       = dataset_train[index_data] \n",
        "    data_train          = data_train[0].unsqueeze(dim=1).to(device)\n",
        "    prediction_train    = compute_prediction(model, data_train)\n",
        "    \n",
        "    plot_data_tensor_grid(prediction_train, index_data, nRow, nCol)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_umdkhbiin6"
      },
      "source": [
        "def function_result_04():\n",
        "\n",
        "    print('[plot examples of the testing original images]')\n",
        "    print('') \n",
        "    \n",
        "    nRow = 8 \n",
        "    nCol = 6\n",
        "    index_data      = np.arange(0, nRow * nCol)\n",
        "    data_test, _    = dataset_test[index_data]\n",
        "    data_test       = data_test[0]\n",
        "    \n",
        "    plot_data_grid(data_test, index_data, nRow, nCol)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9x2Gt2cyiin6"
      },
      "source": [
        "def function_result_05():\n",
        "\n",
        "    print('[plot examples of the testing blur images]')\n",
        "    print('') \n",
        "\n",
        "    nRow = 8\n",
        "    nCol = 6\n",
        "    index_data      = np.arange(0, nRow * nCol)\n",
        "    _, data_test    = dataset_test[index_data]\n",
        "    data_test       = data_test[0]\n",
        "    \n",
        "    plot_data_grid(data_test, index_data, nRow, nCol)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ivVQedD1iin6"
      },
      "source": [
        "def function_result_06():\n",
        "\n",
        "    print('[plot examples of the testing de-blurring results]')\n",
        "    print('') \n",
        "\n",
        "    nRow = 8\n",
        "    nCol = 6\n",
        "    index_data      = np.arange(0, nRow * nCol)\n",
        "    _, data_test    = dataset_test[index_data]\n",
        "    data_test       = data_test[0].unsqueeze(dim=1).to(device)\n",
        "    prediction_test = compute_prediction(model, data_test)\n",
        "    \n",
        "    plot_data_tensor_grid(prediction_test, index_data, nRow, nCol)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UjVxWIoQiin7"
      },
      "source": [
        "def function_result_07():\n",
        "\n",
        "    print('[plot the training loss]')\n",
        "    print('') \n",
        "\n",
        "    plot_curve_error(loss_mean_train, loss_std_train, 'epoch', 'loss', 'loss (training)')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2BxeS2eiin7"
      },
      "source": [
        "def function_result_08():\n",
        "\n",
        "    print('[plot the training accuracy]')\n",
        "    print('') \n",
        "    \n",
        "    plot_curve_error(accuracy_mean_train, accuracy_std_train, 'epoch', 'accuracy', 'accuracy (training)')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dBmJU9hiin7"
      },
      "source": [
        "def function_result_09():\n",
        "    \n",
        "    print('[plot the testing loss]')\n",
        "    print('') \n",
        "    \n",
        "    plot_curve_error(loss_mean_test, loss_std_test, 'epoch', 'loss', 'loss (testing)')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJOpL9imiin7"
      },
      "source": [
        "def function_result_10():\n",
        "    \n",
        "    print('[plot the testing accuracy]') \n",
        "    print('') \n",
        "    \n",
        "    plot_curve_error(accuracy_mean_test, accuracy_std_test, 'epoch', 'accuracy', 'accuracy (testing)')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I5Q-6xZWiin8"
      },
      "source": [
        "def function_result_11():\n",
        "    \n",
        "    print('[print the training loss at the last 10 epochs]')\n",
        "    print('') \n",
        "\n",
        "    data_last   = get_data_last(loss_mean_train, -10)\n",
        "    index       = np.arange(0, 10)\n",
        "    print_curve(data_last, index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xk48CYuiin8"
      },
      "source": [
        "def function_result_12():\n",
        "    \n",
        "    print('[print the training accuracy at the last 10 epochs]')\n",
        "    print('') \n",
        "    \n",
        "    data_last   = get_data_last(accuracy_mean_train, -10)\n",
        "    index       = np.arange(0, 10)\n",
        "    print_curve(data_last, index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYnXMXHFiin8"
      },
      "source": [
        "def function_result_13():\n",
        "    \n",
        "    print('[print the testing loss at the last 10 epochs]')\n",
        "    print('') \n",
        "    \n",
        "    data_last   = get_data_last(loss_mean_test, -10)\n",
        "    index       = np.arange(0, 10)\n",
        "    print_curve(data_last, index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qELwsTaCiin9"
      },
      "source": [
        "def function_result_14():\n",
        "    \n",
        "    print('[print the testing accuracy at the last 10 epochs]')\n",
        "    print('') \n",
        "    \n",
        "    data_last   = get_data_last(accuracy_mean_test, -10)\n",
        "    index       = np.arange(0, 10)\n",
        "    print_curve(data_last, index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HzEfP-9uiin9"
      },
      "source": [
        "def function_result_15():\n",
        "    \n",
        "    print('[print the best training accuracy within the last 10 epochs]')\n",
        "    print('') \n",
        "\n",
        "    value = get_max_last_range(accuracy_mean_train, -10)\n",
        "    print('best training accuracy = %12.10f' % (value))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Djbc5XHiin9"
      },
      "source": [
        "def function_result_16():\n",
        "    \n",
        "    print('[print the best testing accuracy within the last 10 epochs]')\n",
        "    print('') \n",
        "    \n",
        "    value = get_max_last_range(accuracy_mean_test, -10)\n",
        "    print('best testing accuracy = %12.10f' % (value))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQDgGHHpiin-"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UO3Lic6yiin-"
      },
      "source": [
        "# RESULTS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rDQEjFkXiin-"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwrdcAItiin-"
      },
      "source": [
        "number_result = 16\n",
        "\n",
        "for i in range(number_result):\n",
        "\n",
        "    title           = '# RESULT # {:02d}'.format(i+1) \n",
        "    name_function   = 'function_result_{:02d}()'.format(i+1)\n",
        "\n",
        "    print('') \n",
        "    print('################################################################################')\n",
        "    print('#') \n",
        "    print(title)\n",
        "    print('#') \n",
        "    print('################################################################################')\n",
        "    print('') \n",
        "\n",
        "    eval(name_function)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v06_BrI1iin_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}