{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K29I-OwCEYzW",
        "outputId": "db8b297c-a4b8-457a-b43f-7570135306c7"
      },
      "source": [
        "# Image Generation via Generative Adversarial Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ODiv8rJRZiYC"
      },
      "source": [
        "## import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9Wmr9dMLZiYD"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "import os\n",
        "from torchvision.utils import make_grid"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QK2e8feGZiYE"
      },
      "source": [
        "## load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "9xfI-4R9ZiYE",
        "outputId": "1cd2c8fc-e143-434e-b0f1-7868bbef409b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "directory_data  = './drive/MyDrive/Machine_Learning/'\n",
        "filename_data   = 'assignment_12_data.npz'\n",
        "data            = np.load(os.path.join(directory_data, filename_data))\n",
        "\n",
        "real            = torch.from_numpy(data['real_images']).float()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jpOgjgv1ZiYF"
      },
      "source": [
        "## hyper-parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "uiMjm-PXZiYF"
      },
      "outputs": [],
      "source": [
        "device          = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "number_epoch    = 150\n",
        "size_minibatch  = 50\n",
        "dim_latent      = 50\n",
        "dim_channel     = 1\n",
        "learning_rate_discriminator = 0.001\n",
        "learning_rate_generator     = 0.001"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "def affine(image, shear=0, scale=1, rate=[10, 10]):\n",
        "\n",
        "    func_plt = transforms.functional.to_pil_image\n",
        "    func_affine = transforms.functional.affine\n",
        "    func_tensor = transforms.functional.to_tensor\n",
        "\n",
        "    for i in range(len(image)):\n",
        "\n",
        "        # random movement\n",
        "        if rate[0] != 0:\n",
        "            rate_1 = np.random.randint(-rate[0], rate[0]+1)\n",
        "            rate_2 = np.random.randint(-rate[1], rate[1]+1)\n",
        "            movement = [rate_1, rate_2]\n",
        "        else:\n",
        "            movement = rate\n",
        "\n",
        "        if isinstance(scale, list):\n",
        "            rescale = np.random.randint(scale[0], scale[1]+1) / 10\n",
        "        else:\n",
        "            rescale = scale\n",
        "\n",
        "\n",
        "        trans_image = func_plt(image[i])\n",
        "        trans_image = func_affine(trans_image, angle=0, shear=shear, scale=rescale, translate=movement)\n",
        "        trans_image = func_tensor(trans_image)\n",
        "        trans_image = trans_image.numpy()\n",
        "\n",
        "        if i == 0:\n",
        "            image_list = trans_image\n",
        "        else:\n",
        "            image_list = np.concatenate([image_list, trans_image], axis=0)\n",
        "\n",
        "    return image_list"
      ],
      "metadata": {
        "id": "hf7t8raoYE1C"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "real_image = real[::2]\n",
        "affine_12 = affine(real_image, scale=[10, 12], rate=[0, 0])\n",
        "affine_random = affine(real_image, scale=1, rate=[3, 3])"
      ],
      "metadata": {
        "id": "CDCTxOw1YNh1"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QrxulfRFZiYG"
      },
      "source": [
        "## custom data loader for the PyTorch framework"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "yNQe4OUCZiYH"
      },
      "outputs": [],
      "source": [
        "class dataset (Dataset):\n",
        "    def  __init__(self, data):\n",
        "\n",
        "        self.data = data\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        data = self.data[index]\n",
        "        data = torch.FloatTensor(data).unsqueeze(dim=0)\n",
        "\n",
        "        return data\n",
        "  \n",
        "    def __len__(self):\n",
        "        \n",
        "        return self.data.shape[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X2888l7eZiYI"
      },
      "source": [
        "## construct datasets and dataloaders for training and testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "UwcMO-WdZiYI"
      },
      "outputs": [],
      "source": [
        "# image_train = np.concatenate([real[1::2], affine_12, affine_random], axis=0)\n",
        "dataset_real    = dataset(real)\n",
        "dataloader_real = DataLoader(dataset_real, batch_size=size_minibatch, shuffle=True, drop_last=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# image_train.shape"
      ],
      "metadata": {
        "id": "UQiaccCThGlz"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cSai363jZiYI"
      },
      "source": [
        "## shape of the data when using the data loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "mjAvXxDPZiYJ",
        "outputId": "64ba3772-abf3-4200-e030-babeacec6cee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*******************************************************************\n",
            "shape of the image in the training dataset: torch.Size([1, 32, 32])\n",
            "*******************************************************************\n"
          ]
        }
      ],
      "source": [
        "image_real = dataset_real[0]\n",
        "print('*******************************************************************')\n",
        "print('shape of the image in the training dataset:', image_real.shape)\n",
        "print('*******************************************************************')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nlKo6SbwZiYK"
      },
      "source": [
        "## class for the neural network "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "xLd-pfJnZiYK"
      },
      "outputs": [],
      "source": [
        "class Discriminator(nn.Module): \n",
        "\n",
        "\tdef __init__(self, in_channel=1, out_channel=1, dim_feature=128):\n",
        "        \n",
        "\t\tsuper(Discriminator, self).__init__()\n",
        "\n",
        "\t\tself.in_channel \t= in_channel\n",
        "\t\tself.out_channel\t= out_channel\n",
        "\t\tself.dim_feature\t= dim_feature\n",
        "\t\tthreshold_ReLU \t\t= 0.2\n",
        "\t\t\n",
        "\t\tself.feature = nn.Sequential(\n",
        "\t\t\t# ================================================================================\n",
        "\t\t\tnn.Conv2d(in_channel, dim_feature * 1, kernel_size=3, stride=2, padding=1, bias=True),\n",
        "\t\t\tnn.LeakyReLU(threshold_ReLU, inplace=True),\t\t\t\n",
        "\t\t\t# ================================================================================\n",
        "\t\t\tnn.Conv2d(dim_feature * 1, dim_feature * 2, kernel_size=3, stride=2, padding=1, bias=True),\n",
        "\t\t\tnn.LeakyReLU(threshold_ReLU, inplace=True),\t\t\t\n",
        "\t\t\t# ================================================================================\n",
        "\t\t\tnn.Conv2d(dim_feature * 2, dim_feature * 4, kernel_size=3, stride=2, padding=1, bias=True),\n",
        "\t\t\tnn.LeakyReLU(threshold_ReLU, inplace=True),\t\t\t\n",
        "\t\t\t# ================================================================================\n",
        "\t\t\tnn.Conv2d(dim_feature * 4, dim_feature * 8, kernel_size=3, stride=2, padding=1, bias=True),\n",
        "\t\t\tnn.LeakyReLU(threshold_ReLU, inplace=True),\t\t\t\n",
        "\t\t\t# ================================================================================\n",
        "\t\t\tnn.Conv2d(dim_feature * 8, dim_feature * 16, kernel_size=3, stride=2, padding=1, bias=True),\n",
        "\t\t\tnn.LeakyReLU(threshold_ReLU, inplace=True),\t\t\t\n",
        "\t\t\t# ================================================================================\n",
        "\t\t)\t\n",
        "\t\t\n",
        "\t\tself.classifier = nn.Sequential(\n",
        "\t\t\t# ================================================================================\n",
        "\t\t\tnn.Linear(dim_feature * 16, dim_feature * 8, bias=True),\n",
        "\t\t\tnn.LeakyReLU(threshold_ReLU, inplace=True),\t\t\t\n",
        "\t\t\t# ================================================================================\n",
        "\t\t\tnn.Linear(dim_feature * 8, dim_feature * 4, bias=True),\n",
        "\t\t\tnn.LeakyReLU(threshold_ReLU, inplace=True),\t\t\t\n",
        "\t\t\t# ================================================================================\n",
        "\t\t\tnn.Linear(dim_feature * 4, dim_feature * 2, bias=True),\n",
        "\t\t\tnn.LeakyReLU(threshold_ReLU, inplace=True),\t\t\t\n",
        "\t\t\t# ================================================================================\n",
        "\t\t\tnn.Linear(dim_feature * 2, dim_feature * 1, bias=True),\n",
        "\t\t\tnn.LeakyReLU(threshold_ReLU, inplace=True),\t\t\t\n",
        "\t\t\t# ================================================================================\n",
        "\t\t\tnn.Linear(dim_feature * 1, out_channel, bias=True),\n",
        "\t\t\t# ================================================================================\n",
        "\t\t) \n",
        "\n",
        "\t\tself.network = nn.Sequential(\n",
        "\t\t\tself.feature,\n",
        "\t\t\tnn.Flatten(),\n",
        "\t\t\tself.classifier,\n",
        "\t\t)\n",
        "\n",
        "\t\tself.initialize_weight()\n",
        "\n",
        "\t\t# *********************************************************************\n",
        "\t\t# forward propagation\n",
        "\t\t# *********************************************************************\n",
        "\tdef forward(self, x):\n",
        "\n",
        "\t\ty = self.network.forward(x)\n",
        "\n",
        "\t\treturn y\n",
        "\n",
        "\tdef initialize_weight(self):\n",
        "\t\n",
        "\t\tprint('initialize model parameters :', 'xavier_uniform')\n",
        "\n",
        "\t\tfor m in self.network.modules():\n",
        "\t\t\t\n",
        "\t\t\tif isinstance(m, nn.Conv2d):\n",
        "\t\t\t\t\n",
        "\t\t\t\tnn.init.constant_(m.weight, 1)\n",
        "\t\t\t\t\n",
        "\t\t\t\tif m.bias is not None:\n",
        "\n",
        "\t\t\t\t\tnn.init.constant_(m.bias, 1)\n",
        "\t\t\t\t\tpass\n",
        "\t\t\t\t\t\n",
        "\t\t\telif isinstance(m, nn.BatchNorm2d):\n",
        "\t\t\t\t\n",
        "\t\t\t\tnn.init.constant_(m.weight, 1)\n",
        "\t\t\t\tnn.init.constant_(m.bias, 1)\n",
        "\t\t\t\t\n",
        "\t\t\telif isinstance(m, nn.Linear):\n",
        "\t\t\t\t\n",
        "\t\t\t\tnn.init.constant_(m.weight, 1)\n",
        "\n",
        "\t\t\t\tif m.bias is not None:\n",
        "\t\t\t\t\t\n",
        "\t\t\t\t\tnn.init.constant_(m.bias, 1)\n",
        "\t\t\t\t\tpass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "3TkAH7d1ZiYM"
      },
      "outputs": [],
      "source": [
        "class Generator(nn.Module): \n",
        "\n",
        "\tdef __init__(self, in_channel=1, out_channel=1, dim_feature=8):\n",
        "        \n",
        "\t\tsuper(Generator, self).__init__()\n",
        "\n",
        "\t\tself.in_channel \t= in_channel\n",
        "\t\tself.out_channel\t= out_channel\n",
        "\t\tself.dim_feature\t= dim_feature\n",
        "\t\tthreshold_ReLU \t\t= 0.2\n",
        "\n",
        "\t\tself.network = nn.Sequential(\n",
        "\t\t\t# ================================================================================\n",
        "\t\t\tnn.Upsample(scale_factor=2, mode='bilinear', align_corners=False),\n",
        "\t\t\tnn.Conv2d(in_channel, dim_feature * 8, kernel_size=3, stride=1, padding=1, bias=False),\n",
        "\t\t\tnn.BatchNorm2d(dim_feature * 8),\n",
        "\t\t\tnn.LeakyReLU(threshold_ReLU, inplace=True),\n",
        "\t\t\t# ================================================================================\n",
        "\t\t\tnn.Upsample(scale_factor=2, mode='bilinear', align_corners=False),\n",
        "\t\t\tnn.Conv2d(dim_feature * 8, dim_feature * 4, kernel_size=3, stride=1, padding=1, bias=False),\n",
        "\t\t\tnn.BatchNorm2d(dim_feature * 4),\n",
        "\t\t\tnn.LeakyReLU(threshold_ReLU, inplace=True),\n",
        "\t\t\t# ================================================================================\n",
        "\t\t\tnn.Upsample(scale_factor=2, mode='bilinear', align_corners=False),\n",
        "\t\t\tnn.Conv2d(dim_feature * 4, dim_feature * 2, kernel_size=3, stride=1, padding=1, bias=False),\n",
        "\t\t\tnn.BatchNorm2d(dim_feature * 2),\n",
        "\t\t\tnn.LeakyReLU(threshold_ReLU, inplace=True),\n",
        "\t\t\t# ================================================================================\n",
        "\t\t\tnn.Upsample(scale_factor=2, mode='bilinear', align_corners=False),\n",
        "\t\t\tnn.Conv2d(dim_feature * 2, dim_feature * 1, kernel_size=3, stride=1, padding=1, bias=False),\n",
        "\t\t\tnn.BatchNorm2d(dim_feature * 1),\n",
        "\t\t\tnn.LeakyReLU(threshold_ReLU, inplace=True),\n",
        "\t\t\t# ================================================================================\n",
        "\t\t\tnn.Upsample(scale_factor=2, mode='bilinear', align_corners=False),\n",
        "\t\t\tnn.Conv2d(dim_feature * 1, out_channel, kernel_size=3, stride=1, padding=1, bias=False),\n",
        "\t\t\tnn.BatchNorm2d(out_channel),\n",
        "\t\t\t# ================================================================================\n",
        "\t\t\tnn.Sigmoid(),\n",
        "\t\t\t# ================================================================================\n",
        "\t\t) \t\t\t\n",
        "\n",
        "\t\tself.initialize_weight()\n",
        "\t\t\n",
        "\t\t# *********************************************************************\n",
        "\t\t# forward propagation\n",
        "\t\t# *********************************************************************\n",
        "\tdef forward(self, x):\n",
        "\n",
        "\t\ty = self.network.forward(x)\n",
        "\n",
        "\t\treturn y\n",
        "\n",
        "\tdef initialize_weight(self):\n",
        "\t\n",
        "\t\tprint('initialize model parameters :', 'xavier_uniform')\n",
        "\n",
        "\t\tfor m in self.network.modules():\n",
        "\t\t\t\n",
        "\t\t\tif isinstance(m, nn.Conv2d):\n",
        "\t\t\t\t\n",
        "\t\t\t\tnn.init.xavier_uniform_(m.weight)\n",
        "\t\t\t\t\n",
        "\t\t\t\tif m.bias is not None:\n",
        "\n",
        "\t\t\t\t\tnn.init.constant_(m.bias, 1)\n",
        "\t\t\t\t\tpass\n",
        "\t\t\t\t\t\n",
        "\t\t\telif isinstance(m, nn.BatchNorm2d):\n",
        "\t\t\t\t\n",
        "\t\t\t\tnn.init.constant_(m.weight, 1)\n",
        "\t\t\t\tnn.init.constant_(m.bias, 1)\n",
        "\t\t\t\t\n",
        "\t\t\telif isinstance(m, nn.Linear):\n",
        "\t\t\t\t\n",
        "\t\t\t\tnn.init.xavier_uniform_(m.weight)\n",
        "\n",
        "\t\t\t\tif m.bias is not None:\n",
        "\t\t\t\t\t\n",
        "\t\t\t\t\tnn.init.constant_(m.bias, 1)\n",
        "\t\t\t\t\tpass\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_KE-qN1ZiYP"
      },
      "source": [
        "## build network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "lA6RQiZfZiYQ",
        "outputId": "b6575f98-7b77-4e81-f58c-fda0734a4720",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "initialize model parameters : xavier_uniform\n",
            "initialize model parameters : xavier_uniform\n"
          ]
        }
      ],
      "source": [
        "generator       = Generator(dim_latent, 1, 128).to(device)\n",
        "discriminator   = Discriminator(dim_channel, 1, 128).to(device)\n",
        "\n",
        "optimizer_generator     = torch.optim.Adam(generator.parameters(), lr=learning_rate_generator, betas=(0.5, 0.999))\n",
        "optimizer_discriminator = torch.optim.Adam(discriminator.parameters(), lr=learning_rate_discriminator, betas=(0.5, 0.999))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SIm_yasuZiYS"
      },
      "source": [
        "## compute the prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "0mGxiPm4ZiYS"
      },
      "outputs": [],
      "source": [
        "def compute_prediction(model, input):\n",
        "\n",
        "    prediction = model(input)\n",
        "\n",
        "    return prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZQhbkdOZiYS"
      },
      "source": [
        "## compute the loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "2Gi0Von_ZiYS"
      },
      "outputs": [],
      "source": [
        "def compute_loss_discriminator(generator, discriminator, latent, data_real):\n",
        "\n",
        "    data_fake       = compute_prediction(generator, latent)\n",
        "    prediction_real = compute_prediction(discriminator, data_real)\n",
        "    prediction_fake = compute_prediction(discriminator, data_fake)\n",
        "\n",
        "    criterion   = nn.BCEWithLogitsLoss()\n",
        "    \n",
        "    label_real  = torch.ones_like(prediction_real)\n",
        "    label_fake  = torch.zeros_like(prediction_fake)\n",
        "\n",
        "    # ==================================================\n",
        "    # fill up the blank\n",
        "    #    \n",
        "    loss_real = criterion(prediction_real, label_real)\n",
        "    loss_fake = criterion(prediction_fake, label_fake)\n",
        "    # \n",
        "    # ==================================================\n",
        "\n",
        "    loss_discriminator = (loss_real + loss_fake) / 2.0\n",
        "\n",
        "    return loss_discriminator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "w67uMCXkZiYS"
      },
      "outputs": [],
      "source": [
        "def compute_loss_generator(generator, discriminator, latent):\n",
        "\n",
        "    data_fake       = compute_prediction(generator, latent)\n",
        "    prediction_fake = compute_prediction(discriminator, data_fake)\n",
        "\n",
        "    criterion       = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    label_real      = torch.ones_like(prediction_fake)\n",
        "\n",
        "    # ==================================================\n",
        "    # fill up the blank\n",
        "    #    \n",
        "    loss_generator  = criterion(prediction_fake, label_real)\n",
        "    # \n",
        "    # ==================================================\n",
        "\n",
        "    return loss_generator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rnACLB1JZiYT"
      },
      "source": [
        "## compute the accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "g5g3SxP_ZiYU"
      },
      "outputs": [],
      "source": [
        "def get_center_index(binary_image):\n",
        "    \n",
        "    area_square = np.sum(binary_image)\n",
        "\n",
        "    height = binary_image.shape[0]\n",
        "    width = binary_image.shape[1]\n",
        "\n",
        "    x = np.linspace(0, width - 1, width)\n",
        "    y = np.linspace(0, height - 1, height)\n",
        "    indices_X, indices_Y = np.meshgrid(x, y)\n",
        "\n",
        "    x_mean = np.sum(binary_image * indices_X) / area_square\n",
        "    y_mean = np.sum(binary_image * indices_Y) / area_square\n",
        "\n",
        "    return (x_mean, y_mean)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "CF1W_HGhZiYU"
      },
      "outputs": [],
      "source": [
        "# create ideal square image which has the same area to the input image\n",
        "def create_label(binary_images):\n",
        "    \n",
        "    label = np.zeros_like(binary_images)\n",
        "    \n",
        "    for i, binary_image in enumerate(binary_images):\n",
        "        \n",
        "        image_height = binary_image.shape[0]\n",
        "        image_width = binary_image.shape[1]\n",
        "\n",
        "        square_image = np.zeros((image_height, image_width))\n",
        "        square_length = np.round(np.sqrt(np.sum(binary_image)))\n",
        "\n",
        "        if square_length == 0:\n",
        "            # when there is no square\n",
        "            return square_image\n",
        "\n",
        "        (square_center_x, square_center_y) = get_center_index(binary_image)\n",
        "\n",
        "        if square_center_x < 0 or square_center_x > image_width - 1 or square_center_y < 0 or square_center_y > image_height - 1:\n",
        "            return square_image\n",
        "\n",
        "        top = np.ceil(square_center_y - square_length / 2)\n",
        "        bottom = np.floor(square_center_y + square_length / 2)\n",
        "        left = np.ceil(square_center_x - square_length / 2)\n",
        "        right = np.floor(square_center_x + square_length / 2)\n",
        "\n",
        "        top = int(top) if top >= 0 else 0\n",
        "        bottom = int(bottom) if bottom <= image_height - 1 else image_height - 1\n",
        "        left = int(left) if left >= 0 else 0\n",
        "        right = int(right) if right <= image_width - 1 else image_width - 1\n",
        "\n",
        "        square_image[top : bottom + 1, left : right + 1] = 1\n",
        "        \n",
        "        label[i] = square_image\n",
        "        \n",
        "    return label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "gZ5GMpKqZiYU"
      },
      "outputs": [],
      "source": [
        "def compute_accuracy(prediction):\n",
        "\n",
        "    prediction  = prediction.squeeze(axis=1)\n",
        "    \n",
        "    prediction_binary   = (prediction >= 0.5).cpu().numpy().astype(int)\n",
        "    label               = create_label(prediction_binary).astype(int)\n",
        "    \n",
        "    region_intersection = prediction_binary & label\n",
        "    region_union        = prediction_binary | label\n",
        "\n",
        "    area_intersection   = region_intersection.sum(axis=1).sum(axis=1).astype(float)\n",
        "    area_union          = region_union.sum(axis=1).sum(axis=1).astype(float)\n",
        "\n",
        "    eps         = np.finfo(float).eps\n",
        "    correct     = area_intersection / (area_union + eps)\n",
        "    accuracy    = correct.mean() * 100.0\n",
        "    \n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2mS2JQyZiYU"
      },
      "source": [
        "## variables for the learning curve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "OGibNn-WZiYU"
      },
      "outputs": [],
      "source": [
        "loss_generator_mean     = np.zeros(number_epoch)\n",
        "loss_generator_std      = np.zeros(number_epoch)\n",
        "loss_discriminator_mean = np.zeros(number_epoch)\n",
        "loss_discriminator_std  = np.zeros(number_epoch)\n",
        "\n",
        "accuracy_mean   = np.zeros(number_epoch)\n",
        "accuracy_std    = np.zeros(number_epoch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i44O38S9ZiYV"
      },
      "source": [
        "## train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "0D8yRcpxZiYV"
      },
      "outputs": [],
      "source": [
        "def train(generator, discriminator, dataloader):\n",
        "\n",
        "    loss_epoch_generator      = []\n",
        "    loss_epoch_discriminator  = []\n",
        "    accuracy_epoch = []\n",
        "    \n",
        "    for index_batch, data_real in enumerate(dataloader):\n",
        "\n",
        "        size_batch  = len(data_real)\n",
        "        data_real   = data_real.to(device)\n",
        "        \n",
        "        latent  = torch.randn(size_batch, dim_latent, device=device)\n",
        "        latent  = torch.reshape(latent, [size_batch, dim_latent, 1, 1])\n",
        "\n",
        "        # ---------------------------------------------------------------------------\n",
        "        #  \n",
        "        # update the generator\n",
        "        #  \n",
        "        # ---------------------------------------------------------------------------\n",
        "        generator.train()\n",
        "        discriminator.eval()\n",
        "\n",
        "        optimizer_generator.zero_grad()\n",
        "        loss_generator = compute_loss_generator(generator, discriminator, latent)\n",
        "        loss_generator.backward()\n",
        "        optimizer_generator.step()\n",
        "\n",
        "        # ---------------------------------------------------------------------------\n",
        "        #  \n",
        "        # update the discriminator\n",
        "        #  \n",
        "        # ---------------------------------------------------------------------------\n",
        "        generator.eval()\n",
        "        discriminator.train()\n",
        "\n",
        "        optimizer_discriminator.zero_grad()\n",
        "        loss_discriminator = compute_loss_discriminator(generator, discriminator, latent, data_real)\n",
        "        loss_discriminator.backward()\n",
        "        optimizer_discriminator.step()\n",
        "\n",
        "        data_fake   = compute_prediction(generator, latent)\n",
        "        accuracy    = compute_accuracy(data_fake)\n",
        "\n",
        "        loss_epoch_generator.append(loss_generator.item())\n",
        "        loss_epoch_discriminator.append(loss_discriminator.item())\n",
        "        accuracy_epoch.append(accuracy)\n",
        "\n",
        "    loss_generator_mean_epoch       = np.mean(loss_epoch_generator)\n",
        "    loss_generator_std_epoch        = np.std(loss_epoch_generator)\n",
        "    \n",
        "    loss_discriminator_mean_epoch   = np.mean(loss_epoch_discriminator)\n",
        "    loss_discriminator_std_epoch    = np.std(loss_epoch_discriminator)\n",
        "\n",
        "    accuracy_mean_epoch             = np.mean(accuracy_epoch)\n",
        "    accuracy_std_epoch              = np.std(accuracy_epoch)\n",
        "\n",
        "    loss_value_generator        = {'mean' : loss_generator_mean_epoch, 'std' : loss_generator_std_epoch}\n",
        "    loss_value_discriminator    = {'mean' : loss_discriminator_mean_epoch, 'std' : loss_discriminator_std_epoch}\n",
        "    accuracy_value              = {'mean' : accuracy_mean_epoch, 'std' : accuracy_std_epoch} \n",
        "\n",
        "    return loss_value_generator, loss_value_discriminator, accuracy_value\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7gyp-qHZiYV"
      },
      "source": [
        "## training epoch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WcbnvnevZiYV",
        "outputId": "aefef415-485f-40a7-b8ea-eb68d85237ed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  1%|          | 1/150 [00:17<43:12, 17.40s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch : 0\n",
            "\tloss_value_discriminator : 3.787472832741694e+27, acc mean : 79.92073339719686\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|▏         | 2/150 [00:34<42:53, 17.39s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch : 1\n",
            "\tloss_value_discriminator : 3.8035652094314066e+27, acc mean : 78.47367714126277\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 3/150 [00:52<42:33, 17.37s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch : 2\n",
            "\tloss_value_discriminator : 3.793951161094714e+27, acc mean : 78.14854700893792\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  3%|▎         | 4/150 [01:09<42:16, 17.38s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch : 3\n",
            "\tloss_value_discriminator : 3.8037876548572454e+27, acc mean : 78.47878571245688\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  3%|▎         | 5/150 [01:26<41:58, 17.37s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch : 4\n",
            "\tloss_value_discriminator : 3.797497737258254e+27, acc mean : 78.32559169319208\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  4%|▍         | 6/150 [01:44<41:41, 17.37s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch : 5\n",
            "\tloss_value_discriminator : 3.7971870700643856e+27, acc mean : 78.12280326593363\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  5%|▍         | 7/150 [02:01<41:22, 17.36s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch : 6\n",
            "\tloss_value_discriminator : 3.802781605470965e+27, acc mean : 78.3079545107816\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  5%|▌         | 8/150 [02:18<41:04, 17.36s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch : 7\n",
            "\tloss_value_discriminator : 3.798495512207332e+27, acc mean : 78.12529338465868\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  6%|▌         | 9/150 [02:36<40:48, 17.36s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch : 8\n",
            "\tloss_value_discriminator : 3.7952502065520274e+27, acc mean : 78.03716553343259\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  7%|▋         | 10/150 [02:53<40:30, 17.36s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch : 9\n",
            "\tloss_value_discriminator : 3.8021780520285403e+27, acc mean : 78.45901970452051\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  7%|▋         | 11/150 [03:11<40:12, 17.36s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch : 10\n",
            "\tloss_value_discriminator : 3.796645048096286e+27, acc mean : 77.87473927385354\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  8%|▊         | 12/150 [03:28<39:54, 17.35s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch : 11\n",
            "\tloss_value_discriminator : 3.7995992315265595e+27, acc mean : 78.14675859646671\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  9%|▊         | 13/150 [03:45<39:38, 17.36s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch : 12\n",
            "\tloss_value_discriminator : 3.802845971737961e+27, acc mean : 78.36370879022097\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  9%|▉         | 14/150 [04:03<39:20, 17.35s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch : 13\n",
            "\tloss_value_discriminator : 3.799107429317721e+27, acc mean : 78.01411222880671\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 10%|█         | 15/150 [04:20<39:02, 17.35s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch : 14\n",
            "\tloss_value_discriminator : 3.7980098223056925e+27, acc mean : 78.10894702767304\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 11%|█         | 16/150 [04:37<38:45, 17.36s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch : 15\n",
            "\tloss_value_discriminator : 3.799341835097624e+27, acc mean : 78.37989938668267\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 11%|█▏        | 17/150 [04:55<38:30, 17.38s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch : 16\n",
            "\tloss_value_discriminator : 3.799735775184181e+27, acc mean : 78.2075001590864\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 12%|█▏        | 18/150 [05:12<38:12, 17.37s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch : 17\n",
            "\tloss_value_discriminator : 3.7955166461754993e+27, acc mean : 78.13009507667893\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 13%|█▎        | 19/150 [05:30<37:58, 17.40s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch : 18\n",
            "\tloss_value_discriminator : 3.7991058849391474e+27, acc mean : 78.12131120359561\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 13%|█▎        | 20/150 [05:47<37:40, 17.39s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch : 19\n",
            "\tloss_value_discriminator : 3.801358827834286e+27, acc mean : 78.32067218670976\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 14%|█▍        | 21/150 [06:04<37:21, 17.37s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch : 20\n",
            "\tloss_value_discriminator : 3.796165964702989e+27, acc mean : 78.1284974146758\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 15%|█▍        | 22/150 [06:22<37:01, 17.36s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch : 21\n",
            "\tloss_value_discriminator : 3.801717559521317e+27, acc mean : 78.1302627588273\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 15%|█▌        | 23/150 [06:39<36:44, 17.36s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch : 22\n",
            "\tloss_value_discriminator : 3.8016126207132165e+27, acc mean : 78.34027453854871\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 16%|█▌        | 24/150 [06:56<36:27, 17.36s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch : 23\n",
            "\tloss_value_discriminator : 3.799239326111812e+27, acc mean : 78.25048587588003\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 17%|█▋        | 25/150 [07:14<36:07, 17.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch : 24\n",
            "\tloss_value_discriminator : 3.7992857192441633e+27, acc mean : 78.16683665210479\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 17%|█▋        | 26/150 [07:31<35:49, 17.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch : 25\n",
            "\tloss_value_discriminator : 3.7949379435003e+27, acc mean : 77.72213882664161\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 18%|█▊        | 27/150 [07:48<35:31, 17.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch : 26\n",
            "\tloss_value_discriminator : 3.798214665247744e+27, acc mean : 78.06175989520128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 19%|█▊        | 28/150 [08:06<35:13, 17.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch : 27\n",
            "\tloss_value_discriminator : 3.7997563119872576e+27, acc mean : 78.26486561961656\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 19%|█▉        | 29/150 [08:23<34:56, 17.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch : 28\n",
            "\tloss_value_discriminator : 3.8016557294671346e+27, acc mean : 78.23909634568427\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 30/150 [08:40<34:39, 17.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch : 29\n",
            "\tloss_value_discriminator : 3.797225593729916e+27, acc mean : 78.29650239403443\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 21%|██        | 31/150 [08:57<34:21, 17.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch : 30\n",
            "\tloss_value_discriminator : 3.7993989462172763e+27, acc mean : 78.06288571167391\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 21%|██▏       | 32/150 [09:15<34:02, 17.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch : 31\n",
            "\tloss_value_discriminator : 3.799015470153543e+27, acc mean : 78.4214882652731\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|██▏       | 33/150 [09:32<33:45, 17.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch : 32\n",
            "\tloss_value_discriminator : 3.8014197552849913e+27, acc mean : 78.27898707920836\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 23%|██▎       | 34/150 [09:49<33:28, 17.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch : 33\n",
            "\tloss_value_discriminator : 3.8013532028643257e+27, acc mean : 78.38033417126753\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 23%|██▎       | 35/150 [10:07<33:11, 17.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch : 34\n",
            "\tloss_value_discriminator : 3.8002510313556243e+27, acc mean : 78.11809037537824\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 24%|██▍       | 36/150 [10:24<32:53, 17.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch : 35\n",
            "\tloss_value_discriminator : 3.797984823964514e+27, acc mean : 78.37082304467297\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|██▍       | 37/150 [10:41<32:36, 17.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch : 36\n",
            "\tloss_value_discriminator : 3.8045236095907625e+27, acc mean : 78.64069143283503\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|██▌       | 38/150 [10:59<32:19, 17.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch : 37\n",
            "\tloss_value_discriminator : 3.795948138685062e+27, acc mean : 78.07137966324991\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|██▌       | 39/150 [11:16<32:01, 17.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch : 38\n",
            "\tloss_value_discriminator : 3.7993466638546305e+27, acc mean : 78.59627849672037\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 27%|██▋       | 40/150 [11:33<31:44, 17.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch : 39\n",
            "\tloss_value_discriminator : 3.8021052465906275e+27, acc mean : 78.25139371028116\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 27%|██▋       | 41/150 [11:51<31:27, 17.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch : 40\n",
            "\tloss_value_discriminator : 3.8011771780264576e+27, acc mean : 78.29286115105914\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 28%|██▊       | 42/150 [12:08<31:09, 17.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch : 41\n",
            "\tloss_value_discriminator : 3.796972535288797e+27, acc mean : 78.36226347853771\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 29%|██▊       | 43/150 [12:25<30:51, 17.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch : 42\n",
            "\tloss_value_discriminator : 3.8021542514387444e+27, acc mean : 78.38821345472299\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 29%|██▉       | 44/150 [12:43<30:34, 17.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch : 43\n",
            "\tloss_value_discriminator : 3.8032412296942343e+27, acc mean : 78.60501874602392\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 45/150 [13:00<30:16, 17.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch : 44\n",
            "\tloss_value_discriminator : 3.797978011539028e+27, acc mean : 78.44166162489304\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 31%|███       | 46/150 [13:17<29:59, 17.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch : 45\n",
            "\tloss_value_discriminator : 3.797427155725487e+27, acc mean : 78.04098902411246\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 31%|███▏      | 47/150 [13:34<29:42, 17.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch : 46\n",
            "\tloss_value_discriminator : 3.799447559822821e+27, acc mean : 78.2341110424681\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 32%|███▏      | 48/150 [13:52<29:24, 17.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch : 47\n",
            "\tloss_value_discriminator : 3.801929836072237e+27, acc mean : 78.31670825789337\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|███▎      | 49/150 [14:09<29:07, 17.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch : 48\n",
            "\tloss_value_discriminator : 3.799567177091276e+27, acc mean : 78.45399578854145\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|███▎      | 50/150 [14:26<28:50, 17.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch : 49\n",
            "\tloss_value_discriminator : 3.8007939799508684e+27, acc mean : 78.55137944434945\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 34%|███▍      | 51/150 [14:44<28:33, 17.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch : 50\n",
            "\tloss_value_discriminator : 3.7956033681803364e+27, acc mean : 78.1878268166173\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 35%|███▍      | 52/150 [15:01<28:17, 17.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch : 51\n",
            "\tloss_value_discriminator : 3.8031309439043166e+27, acc mean : 78.36833217465976\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 35%|███▌      | 53/150 [15:18<28:00, 17.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch : 52\n",
            "\tloss_value_discriminator : 3.8007230311991964e+27, acc mean : 78.383281317684\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 36%|███▌      | 54/150 [15:36<27:42, 17.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch : 53\n",
            "\tloss_value_discriminator : 3.800720954868003e+27, acc mean : 78.22365299963593\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 37%|███▋      | 55/150 [15:53<27:25, 17.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch : 54\n",
            "\tloss_value_discriminator : 3.800070301311035e+27, acc mean : 78.24881781399691\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 37%|███▋      | 56/150 [16:10<27:08, 17.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch : 55\n",
            "\tloss_value_discriminator : 3.795889562121741e+27, acc mean : 78.08033964469504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|███▊      | 57/150 [16:28<26:50, 17.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch : 56\n",
            "\tloss_value_discriminator : 3.8019528129934594e+27, acc mean : 78.32524997279167\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 39%|███▊      | 58/150 [16:45<26:33, 17.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch : 57\n",
            "\tloss_value_discriminator : 3.7983394407406346e+27, acc mean : 77.85147760443259\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 39%|███▉      | 59/150 [17:02<26:16, 17.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch : 58\n",
            "\tloss_value_discriminator : 3.7982968124600504e+27, acc mean : 78.31947817483797\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 60/150 [17:20<25:59, 17.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch : 59\n",
            "\tloss_value_discriminator : 3.799323607998503e+27, acc mean : 78.32046447415296\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 41%|████      | 61/150 [17:37<25:42, 17.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch : 60\n",
            "\tloss_value_discriminator : 3.797314529344042e+27, acc mean : 78.14087540497425\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 41%|████▏     | 62/150 [17:54<25:24, 17.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch : 61\n",
            "\tloss_value_discriminator : 3.800891941599769e+27, acc mean : 78.45353706852649\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 42%|████▏     | 63/150 [18:12<25:07, 17.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch : 62\n",
            "\tloss_value_discriminator : 3.8017161215332675e+27, acc mean : 78.39660798006953\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 43%|████▎     | 64/150 [18:29<24:50, 17.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch : 63\n",
            "\tloss_value_discriminator : 3.79790004787668e+27, acc mean : 78.10313420779033\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 43%|████▎     | 65/150 [18:46<24:32, 17.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch : 64\n",
            "\tloss_value_discriminator : 3.7993544200670227e+27, acc mean : 78.35368444580325\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 44%|████▍     | 66/150 [19:04<24:14, 17.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch : 65\n",
            "\tloss_value_discriminator : 3.801544005689167e+27, acc mean : 78.174462464402\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 45%|████▍     | 67/150 [19:21<23:57, 17.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch : 66\n",
            "\tloss_value_discriminator : 3.797629819377774e+27, acc mean : 78.24511420007806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 45%|████▌     | 68/150 [19:38<23:40, 17.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch : 67\n",
            "\tloss_value_discriminator : 3.7989449332361577e+27, acc mean : 78.10207221736135\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 46%|████▌     | 69/150 [19:55<23:22, 17.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch : 68\n",
            "\tloss_value_discriminator : 3.7960775747692926e+27, acc mean : 78.17389470221292\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 47%|████▋     | 70/150 [20:13<23:05, 17.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch : 69\n",
            "\tloss_value_discriminator : 3.8041713814535023e+27, acc mean : 78.6309329263675\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 47%|████▋     | 71/150 [20:30<22:47, 17.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch : 70\n",
            "\tloss_value_discriminator : 3.7987592920677046e+27, acc mean : 78.10271424361306\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 48%|████▊     | 72/150 [20:47<22:30, 17.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch : 71\n",
            "\tloss_value_discriminator : 3.796773705127325e+27, acc mean : 78.02850547315595\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 49%|████▊     | 73/150 [21:05<22:12, 17.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch : 72\n",
            "\tloss_value_discriminator : 3.8012199367212325e+27, acc mean : 78.09452952536601\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 49%|████▉     | 74/150 [21:22<21:55, 17.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch : 73\n",
            "\tloss_value_discriminator : 3.7996899140044493e+27, acc mean : 78.0841446205514\n"
          ]
        }
      ],
      "source": [
        "# ================================================================================\n",
        "# \n",
        "# iterations for epochs\n",
        "#\n",
        "# ================================================================================\n",
        "for i in tqdm(range(number_epoch)):\n",
        "    \n",
        "    # ================================================================================\n",
        "    # \n",
        "    # training\n",
        "    #\n",
        "    # ================================================================================\n",
        "    (loss_value_generator, loss_value_discriminator, accuracy_value) = train(generator, discriminator, dataloader_real)\n",
        "\n",
        "    loss_generator_mean[i]      = loss_value_generator['mean']\n",
        "    loss_generator_std[i]       = loss_value_generator['std']\n",
        "\n",
        "    loss_discriminator_mean[i]  = loss_value_discriminator['mean']\n",
        "    loss_discriminator_std[i]   = loss_value_discriminator['std']\n",
        "\n",
        "    accuracy_mean[i]            = accuracy_value['mean']\n",
        "    accuracy_std[i]             = accuracy_value['std']\n",
        "\n",
        "    print(f\"epoch : {i}\")\n",
        "    print(f\"\\tloss_value_discriminator : {loss_value_discriminator['mean']}, acc mean : {accuracy_value['mean']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGpzL2sHZiYV"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sig1-Xv-ZiYW"
      },
      "source": [
        "# functions for visualizing the results "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mo8Kr3FzZiYW"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5BarCiNZiYW"
      },
      "source": [
        "## plot curve"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oh-F0VPWZiYW"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IllnUpY9ZiYW"
      },
      "outputs": [],
      "source": [
        "def plot_image_grid(data, nRow, nCol, filename=None):\n",
        "\n",
        "    size_col = 1.5\n",
        "    size_row = 1.5\n",
        "\n",
        "    fig, axes = plt.subplots(nRow, nCol, constrained_layout=True, figsize=(nCol * size_col, nRow * size_row))\n",
        "    \n",
        "    data = data.detach().cpu()\n",
        "\n",
        "    for i in range(nRow):\n",
        "        for j in range(nCol):\n",
        "\n",
        "            k       = i * nCol + j\n",
        "            image   = np.squeeze(data[k], axis=0)\n",
        "\n",
        "            axes[i, j].imshow(image, cmap='gray', vmin=0, vmax=1)\n",
        "            axes[i, j].xaxis.set_visible(False)\n",
        "            axes[i, j].yaxis.set_visible(False)\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "    if filename is not None:\n",
        "\n",
        "        fig.savefig(filename)\n",
        "        pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qowDwzLAZiYW"
      },
      "outputs": [],
      "source": [
        "def plot_data_grid(data, index_data, nRow, nCol):\n",
        "    \n",
        "    size_col = 1.5\n",
        "    size_row = 1.5\n",
        "\n",
        "    fig, axes = plt.subplots(nRow, nCol, constrained_layout=True, figsize=(nCol * size_col, nRow * size_row))\n",
        "\n",
        "    for i in range(nRow):\n",
        "        for j in range(nCol):\n",
        "\n",
        "            k       = i * nCol + j\n",
        "            index   = index_data[k]\n",
        "\n",
        "            axes[i, j].imshow(data[index], cmap='gray', vmin=0, vmax=1)\n",
        "            axes[i, j].xaxis.set_visible(False)\n",
        "            axes[i, j].yaxis.set_visible(False)\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rMGtJBm7ZiYW"
      },
      "outputs": [],
      "source": [
        "def plot_data_tensor_grid(data, index_data, nRow, nCol):\n",
        "    \n",
        "    size_col = 1.5\n",
        "    size_row = 1.5\n",
        "\n",
        "    fig, axes = plt.subplots(nRow, nCol, constrained_layout=True, figsize=(nCol * size_col, nRow * size_row))\n",
        "\n",
        "    data = data.detach().cpu().squeeze(axis=1)\n",
        "\n",
        "    for i in range(nRow):\n",
        "        for j in range(nCol):\n",
        "\n",
        "            k       = i * nCol + j\n",
        "            index   = index_data[k]\n",
        "\n",
        "            axes[i, j].imshow(data[index], cmap='gray', vmin=0, vmax=1)\n",
        "            axes[i, j].xaxis.set_visible(False)\n",
        "            axes[i, j].yaxis.set_visible(False)\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k9Rvahj_ZiYX"
      },
      "outputs": [],
      "source": [
        "def plot_curve_error(data_mean, data_std, x_label, y_label, title, filename=None):\n",
        "\n",
        "    fig = plt.figure(figsize=(8, 6))\n",
        "    plt.title(title)\n",
        "\n",
        "    alpha = 0.3\n",
        "    \n",
        "    plt.plot(range(len(data_mean)), data_mean, '-', color = 'red')\n",
        "    plt.fill_between(range(len(data_mean)), data_mean - data_std, data_mean + data_std, facecolor = 'blue', alpha = alpha) \n",
        "    \n",
        "    plt.xlabel(x_label)\n",
        "    plt.ylabel(y_label)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    if filename is not None:\n",
        "\n",
        "        fig.savefig(filename)\n",
        "        pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mrTtty56ZiYX"
      },
      "outputs": [],
      "source": [
        "def print_curve(data, index):\n",
        "    \n",
        "    for i in range(len(index)):\n",
        "\n",
        "        idx = index[i]\n",
        "        val = data[idx]\n",
        "\n",
        "        print('index = %2d, value = %12.10f' % (idx, val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lIZj7BMNZiYX"
      },
      "outputs": [],
      "source": [
        "def get_data_last(data, index_start):\n",
        "\n",
        "    data_last = data[index_start:]\n",
        "\n",
        "    return data_last"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hSWP-LXEZiYX"
      },
      "outputs": [],
      "source": [
        "def get_max_last_range(data, index_start):\n",
        "\n",
        "    data_range = get_data_last(data, index_start)\n",
        "    value = data_range.max()\n",
        "\n",
        "    return value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jJl9ZgUxZiYX"
      },
      "outputs": [],
      "source": [
        "def get_min_last_range(data, index_start):\n",
        "\n",
        "    data_range = get_data_last(data, index_start)\n",
        "    value = data_range.min()\n",
        "\n",
        "    return value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JOdRbokrZiYX"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ukEa2-2ZiYY"
      },
      "source": [
        "# functions for presenting the results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VyWYXuUpZiYY"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MEe41fgTZiYY"
      },
      "outputs": [],
      "source": [
        "def function_result_01():\n",
        "\n",
        "    print('[plot examples of the real images]')\n",
        "    print('') \n",
        "\n",
        "    nRow = 8\n",
        "    nCol = 6\n",
        "\n",
        "    number_data = len(dataset_real)\n",
        "    step        = int(np.floor(number_data / (nRow * nCol)))\n",
        "    index_data  = np.arange(0, number_data, step)\n",
        "    index_plot  = np.arange(0, nRow * nCol)\n",
        "\n",
        "    data = dataset_real[index_data]\n",
        "    data = data[0]\n",
        "    \n",
        "    plot_data_grid(data, index_plot, nRow, nCol)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UL9Dr3NaZiYY"
      },
      "outputs": [],
      "source": [
        "def function_result_02():\n",
        "\n",
        "    print('[plot examples of the fake images]')\n",
        "    print('') \n",
        "\n",
        "    nRow = 8\n",
        "    nCol = 6\n",
        "    number_latent = nRow * nCol\n",
        "\n",
        "    latent  = torch.randn(number_latent, dim_latent, device=device)\n",
        "    latent  = torch.reshape(latent, [number_latent, dim_latent, 1, 1])\n",
        "\n",
        "    generator.eval()\n",
        "\n",
        "    data_fake   = generator(latent)\n",
        "    filename    = 'fake_image.png'\n",
        "\n",
        "    plot_image_grid(data_fake, nRow, nCol, filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8sXOPrEkZiYY"
      },
      "outputs": [],
      "source": [
        "def function_result_03():\n",
        "\n",
        "    print('[plot the generator loss]')\n",
        "    print('') \n",
        "\n",
        "    plot_curve_error(loss_generator_mean, loss_generator_std, 'epoch', 'loss', 'generator loss', 'loss_generator.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EZ7wWBKmZiYY"
      },
      "outputs": [],
      "source": [
        "def function_result_04():\n",
        "    \n",
        "    print('[plot the discriminator loss]')\n",
        "    print('') \n",
        "    \n",
        "    plot_curve_error(loss_discriminator_mean, loss_discriminator_std, 'epoch', 'loss', 'discriminator loss', 'loss_discriminator.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z4GVlcfwZiYY"
      },
      "outputs": [],
      "source": [
        "def function_result_05():\n",
        "    \n",
        "    print('[plot the accuracy]')\n",
        "    print('') \n",
        "    \n",
        "    plot_curve_error(accuracy_mean, accuracy_std, 'epoch', 'accuracy', 'training accuracy', 'training_accuracy.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DfgfXKPuZiYY"
      },
      "outputs": [],
      "source": [
        "def function_result_06():\n",
        "    \n",
        "    print('[print the generator loss at the last 10 epochs]')\n",
        "    print('') \n",
        "\n",
        "    data_last = get_data_last(loss_generator_mean, -10)\n",
        "    index = np.arange(0, 10)\n",
        "    print_curve(data_last, index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HgAGW3flZiYZ"
      },
      "outputs": [],
      "source": [
        "def function_result_07():\n",
        "    \n",
        "    print('[print the discriminator loss at the last 10 epochs]')\n",
        "    print('') \n",
        "\n",
        "    data_last = get_data_last(loss_discriminator_mean, -10)\n",
        "    index = np.arange(0, 10)\n",
        "    print_curve(data_last, index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m25LJAC-ZiYZ"
      },
      "outputs": [],
      "source": [
        "def function_result_08():\n",
        "    \n",
        "    print('[print the accuracy at the last 10 epochs]')\n",
        "    print('') \n",
        "\n",
        "    data_last = get_data_last(accuracy_mean, -10)\n",
        "    index = np.arange(0, 10)\n",
        "    print_curve(data_last, index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kecDyh2GZiYZ"
      },
      "outputs": [],
      "source": [
        "def function_result_09():\n",
        "    \n",
        "    print('[print the best accuracy within the last 10 epochs]')\n",
        "    print('') \n",
        "    \n",
        "    value = get_max_last_range(accuracy_mean, -10)\n",
        "    print('best accuracy = %12.10f' % (value))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZbp5pPOZiYZ"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TU1P0Y7qZiYZ"
      },
      "source": [
        "# RESULTS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DuWnhH62ZiYZ"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XP0f5JD9ZiYa"
      },
      "outputs": [],
      "source": [
        "number_result = 9\n",
        "\n",
        "for i in range(number_result):\n",
        "\n",
        "    title           = '# RESULT # {:02d}'.format(i+1) \n",
        "    name_function   = 'function_result_{:02d}()'.format(i+1)\n",
        "\n",
        "    print('') \n",
        "    print('################################################################################')\n",
        "    print('#') \n",
        "    print(title)\n",
        "    print('#') \n",
        "    print('################################################################################')\n",
        "    print('') \n",
        "\n",
        "    eval(name_function)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "assignment_02.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "17ed1555cfbb96ddcf655400d6c25a9cebe961c1b69daf25bae91d698acdd2a7"
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 64-bit ('hsh': conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}